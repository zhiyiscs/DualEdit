model_name: "minigpt-4-vicuna-7b"
num_layers: 32
layer_module_tmp: "llama_model.model.layers.{}"
mlp_module_tmp: "llama_model.model.layers.{}.mlp"
attn_module_tmp: "llama_model.model.layers.{}.self_attn"
qproj_module_tmp: "llama_model.model.layers.{}.self_attn.q_proj"
kvproj_module_tmp: "llama_model.model.layers.{}.self_attn.k_proj"
vproj_module_tmp: "llama_model.model.layers.{}.self_attn.v_proj"
oproj_module_tmp: "llama_model.model.layers.{}.self_attn.o_proj"
norm_path: "llama_model.model.norm"
voc_path: "llama_model.lm_head"


